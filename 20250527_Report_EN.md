**<font style="color:rgb(38, 38, 38);">「AI Surpasses Cloud Native as the Most Influential Tech Domain」</font>**

<font style="color:rgb(38, 38, 38);">According to OpenRank data from </font>[OpenDigger](https://github.com/X-lab2017/open-digger)<font style="color:rgb(38, 38, 38);">, AI surpassed Cloud Native in 2023 to become the most influential technology domain in terms of total collaboration events count. Looking at the growth curves of the five major tech domains (AI, Cloud Native, Database, Frontend, and Operating System) over the past decade, AI projects have seen rapid growth, especially after 2022. AI’s total influence score overtook Frontend technologies in 2017, accelerated post-2022, and surpassed the declining Cloud Native in 2023 to claim the top spot.</font>

<font style="color:#8A8F8D;">OpenRank details: https://open-digger.cn/docs/user_docs/metrics/global_openrank</font>

![](https://intranetproxy.alipay.com/skylark/lark/0/2025/png/51756374/1748180031873-6883d635-fddc-48af-945f-9ce2ba767953.png)



## The LLM Development Ecosystem: A Snapshot
During the 2025 Chinese New Year, DeepSeek sparked a surge in the Large Language Model (LLM) development ecosystem. <font style="color:rgb(51, 51, 51);">In February 2025, GitHub’s Weekly Trending List reached a peak where </font>**<font style="color:rgb(51, 51, 51);">94% of the listed repositories were AI-related</font>**<font style="color:rgb(51, 51, 51);">.</font> This ecosystem is incredibly new and fastly evolving. Over the past three months, we observed that 60% of LLM-related projects appeared on GitHub Trending were emerged after 2024, and nearly 21% were created in just the last six months. That said, these violent delights have violent ends. We also observed that many once-popular projects faded into the void before this published report as the victims of the blazingly fast iterative speed.



The reason why Ant Group's Open Source team (with OSPO's job functions and more) to initiate this landscape project is to understand the full picture of the LLM development ecosystem, including emerging trends and cutting-edge popular projects. One of our missions is to leverage insights from the open-source community to guide Ant Group’s architectural and technological decisions. This landscape and trending analysis aim to provide pivotal guidances to open source technical project selection, with both community highlights and potential pitfalls.

<font style="color:#8A8F8D;"></font>

<font style="color:rgb(51, 51, 51);">One of the key advantages of the open-source development ecosystem is that we can analyze collaboration patterns and dynamics among developers through public data, enabling us to model relationships and ecological positions of projects, regardless if they are upstream-downstream partners or competitors in the same niche.</font>

<font style="color:rgb(51, 51, 51);">We build the landscape by first selecting well-known AI projects (e.g., PyTorch, LangChain, vLLM) as seed nodes. By analyzing developer collaboration relationships across "related" GitHub projects, we explored multiple facets of the ecosystem and generated the "initial project list". Based on the initial project list, we collaborated with developers in relevant fields to manually maintain technical domain tags and then iteratively refine the list, until it reaches critical mass.</font>

<font style="color:rgb(51, 51, 51);">Given the rapid iteration of AI technologies, this report aim to highlight cutting-edge and highly active open-source projects u to the time of authoring. To achieve this, we rely on the OpenRank influence metric developed by the X-lab at East China Normal University as a core criterion: only projects with an </font>**<font style="color:rgb(51, 51, 51);">average monthly OpenRank score exceeding 10 in year 2025</font>**<font style="color:rgb(51, 51, 51);"> are included in the landscape. </font>

<font style="color:#8A8F8D;">OpenRank details: https://open-digger.cn/docs/user_docs/metrics/global_openrank</font>



As of May 2025, the Open Source LLM Development Landscape 2025 presented below includes 135 projects across 19 technical domains, spanning both agent application layers and model infrastructure layers. <font style="color:rgb(51, 51, 51);">While we have made significant efforts to extract deeper insights from this data, we are fully aware that community data is neither comprehensive nor entirely accurate, and may not fully reflect emerging or exceptional technological advancements. This report aims to provide valuable inspirations rather than definitive conclusions. We welcome feedback on any omissions, inaccuracies, or additional perspectives to further enhance and improve this work.</font>

![https://antoss-landscape.my.canva.site](https://intranetproxy.alipay.com/skylark/lark/0/2025/png/51756374/1748176573674-2f386be5-a6c0-4a99-8a64-d5438ac1b97b.png)



Below are the details of projects that are ranked in the Top 20 of OpenRank among all the projects in the landscape:

![](https://intranetproxy.alipay.com/skylark/lark/0/2025/png/51756374/1748179153557-68b0111a-d4ce-4e20-b7d0-0cb7e1d0b5ad.png)

![](https://intranetproxy.alipay.com/skylark/lark/0/2025/png/51756374/1748174534587-63d0d0c4-e78b-4b2f-a45f-ae42be01f1f3.png)



Based on the ranking distribution of these projects and comparing the year-over-year absolute changes in OpenRank between 2024 and 2025, three dominant technology trends emerge:

+ **Model Training Frameworks：**PyTorch remains the undisputed leader in the ecosystem, ranking first in OpenRank influence among all projects in the landscape. Meanwhile, Baidu's PaddlePaddle, a Chinese homegrown deep learning platform, saw a 41% drop in OpenRank compared to the previous year, with an absolute decrease of 150 points.
+ **Efficient Inference Engines**: The high-performance inference engines vLLM and SGLang have undergone rapid iteration over the past year, ranking first and third, respectively, in OpenRank growth. Their superior GPU inference performance has made them popular choices for enterprise-level LLM deployment.
+ **Low-Code Application(Agent) Development Frameworks:** Agent platforms like Dify and RAGFlow, which integrate RAG-based knowledge retrieval and management, are experiencing rapid growth as they meet the demand for quickly building AI applications. Notably, both platforms are strong projects emerging from China’s developer community.



After observing over 100 open-source projects in the field of large model development, we’ve arrived at a bold claim: 

### **The LLM Development Ecosystem is **A Real-world Hackathon
![](https://intranetproxy.alipay.com/skylark/lark/0/2025/png/51756374/1748176889363-a03dcbb3-3e8e-4b0b-acbc-2adb070be934.png)  




With the pace of AI technology diffusion far exceeding expectations, the large model development ecosystem has transformed into a real-world live and public Hackathon. Developers, empowered by AI, are now functioning as "super individuals," rapidly building open-source projects around trending topics. They leverage their technical skills to capture public attention and assert influence within the industry. At the same time, waves of open-source projects and products surge in popularity or fade into obscurity amidst the shifting tides of technology trends. This cycle of rapid creation and dissolution, driven by a focus on speed and iteration, mirrors the essence of a Hackathon—where software is built in a matter of hours.



While exploring open-source projects tied to this landscape, we uncovered some intriguing narratives that further reinforce the above point:

### Developers' Short-Term Investments to Gain Professional Reputation
When closed-source projects like Devin, Perplexity, and Manus shook the industry, developers quickly replicated open-source versions:

+ **Devin & OpenDevin**: In March 2024, shortly after Devin’s release, Xingyao Wang, a PhD candidate at UIUC, launched OpenDevin. Within a month, its OpenRank skyrocketed to 190. Later rebranded as OpenHands, it evolved into All Hands AI, a commercial venture focusing on AI software development platforms.
+ **Perplexity & Perplexica**: Independent developer _ItzCrazyKns_ created Perplexica in 2024 as an open-source alternative to the popular closed-source AI search engine Perplexity. While it amassed 22K GitHub stars, its OpenRank plateaued around 25. Interestingly, the same developer launched a lighter version, “Not Devin,” around the same time as Devin’s release, though it’s now abandoned.
+ **Manus & OpenManus**: In March 2024, as Manus went viral, DeepWisdom, the company behind MetaGPT, pulled off a classic “3-hour replication” with OpenManus, which garnered 8K stars on its first day of repository creation.



The longevity of these projects remains to be seen (some have already faded), but developers gained significant technical reputation in the short term. Metrics like GitHub stars, community engagement, and collaborations with leading institutions have become new benchmarks for developers' “influence capital.” Even if these projects end up in the “AI Graveyard,” developers still benefit from early contributions through industry recognition.

### <font style="color:rgb(13, 18, 57);">The AI Graveyard: Ephemeral Technical Experiments</font>
<font style="color:rgb(13, 18, 57);">  
</font><font style="color:rgb(13, 18, 57);">The LLM wave also spawned a slew of “born-to-die” AI projects and products. Out of 5,079 AI tools cataloged by Dang AI, 1,232 have been abandoned, with writing tools being the most likely to shut down. Dang AI even created an “</font>[AI Graveyard](https://dang.ai/ai-graveyard)<font style="color:rgb(13, 18, 57);">” for these fleeting innovations.</font>

<font style="color:rgb(13, 18, 57);"></font>

The open-source ecosystem is no exception. We’ve curated an “Open-Source AI Graveyard” for projects that gained massive attention upon launch but are now inactive. All these projects were launched after 2023 and almost all gained tens of thousands of GitHub stars. While OpenAI officially discontinued Swarm in March of this year, <font style="color:rgb(51, 51, 51);">the remaining projects’ latest code commits remained frozen in 2024.</font>. 



![](https://intranetproxy.alipay.com/skylark/lark/0/2025/png/51756374/1748176965438-56a5b70b-6c72-4e3a-a3e5-3dd9c3e3d0c7.png)



<font style="color:rgb(51, 51, 51);">Two of the most interesting projects in this list are:</font>

+ BabyAGI: Launched in April 2023 by individual developer Yohei, it pioneered the concept of “self-evolving agents,” simulating AGI through task decomposition, learning feedback, and dynamic planning.
+ Swarm: Released by OpenAI in February 2024, it introduced the idea of “swarm intelligence” and was hailed as a groundbreaking exploration of multi-agent collaboration. However, it’s since been overshadowed by the more practical OpenAI Agents SDK.

Both projects were explicitly experimental, almost never intended for long-term planning. Yet, their bold concepts and the discussions they sparked have propelled the “Hackathon relay race” from proof-of-concept to practical implementation.

### Model Capabilities Reshaping Application Scenarios
As model capabilities evolve, the application development ecosystem is undergoing transformation—bringing both disruption and new opportunities.

**The Decline of AI Search Projects**: AI search was one of the earliest applications, with products like Perplexity posing a real challenge to Google. Open-source projects like Morphic.sh and Scira attempted to break the monopoly with localized deployments and customizable APIs. However, their survival rates are low. The generalization of model capabilities, such as GPT-4 and Gemini 2.0, which can autonomously handle web retrieval, information synthesis, and answer generation, is squeezing the market for specialized search tools.

![](https://intranetproxy.alipay.com/skylark/lark/0/2025/png/51756374/1748089695720-b9843d3b-cdc8-4e6b-9ace-55ee64a58b54.png)



**The Rise of AI Coding Projects**: On the flip side, advancements in model capabilities are revolutionizing software development. Claude 3.7 Sonnet’s prowess in coding and web development has ushered in a new era of “Vibe Coding,” where developers describe scenarios in natural language, and models autonomously handle requirements analysis and code implementation. Beyond commercial products like Cursor and Windsurf, IDE plugins like Continue and Cline are thriving open-source options, each with over 3,000 community contributors and steadily rising OpenRank scores. On a side note, Ant Group also open-sourced an AI coding platform, [CodeFuse](https://github.com/codefuse-ai), in 2023. It supports developers throughout the entire software development lifecycle, enabling AI-native software creation. While it doesn’t appear in this Landscape, it’s definitely worth checking out.

![](https://intranetproxy.alipay.com/skylark/lark/0/2025/png/51756374/1748174911901-32a57d5a-6814-4295-8162-dc7b49063eb5.png)



### Dynamic Competition Across Ecosystem Niches
The ecosystem is witnessing dynamic interplay between different niches:

![](https://intranetproxy.alipay.com/skylark/lark/0/2025/png/51756374/1748177241090-43c5fc91-56a8-43cf-aec5-b905a3371477.png)

+ **<font style="color:rgb(51, 51, 51);">Divergent trajectories of Agent Frameworks:</font>**<font style="color:rgb(51, 51, 51);"> At the two extremes of this growth spectrum are application platforms like Dify and application development frameworks like LangChain. The starkly divergent trajectories—'polar opposites' in performance—between these development paradigms exemplify the ecosystem's rapid iteration and extraordinary vitality. A special mention is warranted for DB-GPT, the open-source project initiated by Ant Group and the only one featured in the ecosystem map: it is an Agent development platform that integrates AI application development with big data applications. Its precise positioning and strategic entry enabled the project to quickly garner attention from academic and industrial developers immediately after its 2023 launch, fostering widespread collaborative participation.</font>



+ **The Rise of Reinforcement Learning**: DeepSeek-R1’s “Aha Moment” demonstrated the effectiveness of reinforcement learning as a post-training approach. Reinforcement learning frameworks like Verl and OpenRLHF have seen remarkable growth this year. In February, [inclusionAI](https://github.com/inclusionAI/AReaL) fully open-sourced their reinforcement learning framework AReaL, designed to train large inference models that anyone can reproduce and contribute to. While the project is still in its early stages, we're excited to see if it will make the cut for future landscape overviews.



+ **Blurring Technical Boundaries**: <font style="color:rgb(51, 51, 51);">The boundaries between ecosystems are being dynamically redefined. For instance, vectorized storage, computation, and retrieval—critical components for integrating domain-specific knowledge into large model applications—once drove a surge in popularity for specialized vector databases like Milvus and Qdrant. Meanwhile, traditional big data systems have also embraced vectorization: Ant Group’s open-source distributed database OceanBase added vector storage support last year and achieved API compatibility with Milvus. This evolving landscape reveals how technological boundaries remain fluid and interconnected, maintaining a delicate ecological equilibrium through continuous convergence and innovation.</font>



## Navigating the Tech Trends in Large Model Open-Source Development Ecosystems
Beyond the Landscape, <font style="color:rgb(51, 51, 51);">our analysis of community data highlights seven dominant trends, supported by industry insights and bold forecasts for emerging opportunities. </font>These include emerging paradigms in the LLM era—such as Agent Frameworks, AI-native protocols like MCP, and Coding Agents in the application-layer revolutionizing development workflows—as well as transformations in traditional domains like big data and ML. Some areas experienced significant disruption (e.g., vectorized storage), while others saw significant ecosystem realignment (e.g., model inference services).



![](https://intranetproxy.alipay.com/skylark/lark/0/2025/png/51756374/1748177537308-62243e77-1a66-40ff-b096-ba21c384498e.png)



### The Agent Frameworks Boom Diverged in 2025
![](https://intranetproxy.alipay.com/skylark/lark/0/2025/png/51756374/1748500445962-846f0964-5db2-4db7-9345-af91bf607b0d.png)

![](https://intranetproxy.alipay.com/skylark/lark/0/2025/png/51756374/1748178277239-535b4014-4be7-4cae-bca1-11f92b490dd7.png)



![OpenRank Top 10 Project Ranking Trend](https://intranetproxy.alipay.com/skylark/lark/0/2025/png/85156528/1748187265889-17494895-c8f1-4078-beb4-7244c0d5d6ad.png)



![](https://intranetproxy.alipay.com/skylark/lark/0/2025/png/51756374/1748100736421-89fb3bd5-dcbb-4dc7-b19f-830a555f2f40.png)



During 2023 and 2024, "universal" frameworks like LangChain dominated the market with pioneering task orchestration and tool integration capabilities. This period saw an explosion of new Agent frameworks—whether specialized in tool invocation, RAG integration, long-context memory, or ReAct planning—each rapidly emerging alongside evolving technical concepts. By late 2024, the landscape began consolidating, with few new entrants.

As the hype subsided, early leaders like LangChain declined due to steep learning curves and complex debugging overhead. By 2025, a clear divergence emerged:

+ Platforms like Dify and RAGFlow took the lead through low-code workflows and enterprise-grade solutions.
+ Traditional frameworks like LangChain and LlamaIndex gradually lost relevance.



<font style="color:rgb(64, 64, 64);">Dify, currently the hottest AI application platform, nailed enterprise needs by:</font>

+ <font style="color:rgb(64, 64, 64);">Drastically reducing technical barriers via intuitive visual workflow design</font>
+ <font style="color:rgb(64, 64, 64);">Offering robust enterprise security controls</font>

**<font style="color:rgb(64, 64, 64);">For developers today, usability and rapid prototyping define success—not new framework options. </font>**<font style="color:rgb(64, 64, 64);">Below, we compare three leading frameworks’ key features:</font>

| **<font style="color:#FFFFFF;">Feature</font>** | **<font style="color:#FFFFFF;">Dify</font>** | **<font style="color:#FFFFFF;">n8n</font>** | **<font style="color:#FFFFFF;">RAGFlow</font>** |
| :--- | :--- | :--- | :--- |
| <font style="color:rgb(25, 27, 31);">Workflow Orchestration Support</font> | ✅<font style="color:rgb(25, 27, 31);"> Provides visual AI workflow orchestration, supporting the breakdown of complex tasks into nodes</font> | ✅<font style="color:rgb(25, 27, 31);"> Provides visual general-purpose workflow orchestration using a drag-and-drop interface for building automation flows</font> | ⚠️<font style="color:rgb(25, 27, 31);"> Partial Support: Focuses on RAG processes; offers a Graph-based workflow primarily for retrieval pipelines.</font> |
| <font style="color:rgb(25, 27, 31);">Visual Interface</font> | <font style="color:rgb(25, 27, 31);"> </font>✅<font style="color:rgb(25, 27, 31);"> Includes a web-based visual "Canvas" interface for building and testing AI workflows</font> | ✅<font style="color:rgb(25, 27, 31);"> Features a web-based visual flow editor (WYSIWYG - What You See Is What You Get) for building workflows</font> | ⚠️<font style="color:rgb(25, 27, 31);"> Limited Capabilities: Provides a web interface for document upload and chat interaction, but lacks a general-purpose visual workflow design interface</font> |
| <font style="color:rgb(25, 27, 31);">AI/LLM Integration</font> | ✅<font style="color:rgb(25, 27, 31);"> Deep integration with various LLMs; supports numerous models (hundreds) and inference providers (dozens)</font> | ✅<font style="color:rgb(25, 27, 31);"> Built-in AI nodes support LangChain, calling models like OpenAI, etc.; supports custom code nodes to call any model API</font> | ✅<font style="color:rgb(25, 27, 31);"> Integrated LLMs for Q&A; supports multiple major model providers; models are configurable and switchable</font> |
| <font style="color:rgb(25, 27, 31);">Document/RAG Pipeline</font> | ✅<font style="color:rgb(25, 27, 31);"> Built-in RAG pipeline covering the entire process from ingestion to retrieval; supports automatic text parsing of formats like PDF, PPT</font> | ⚠️<font style="color:rgb(25, 27, 31);"> Indirect Support: No native RAG module, but retrieval + Q&A can be implemented via node combinations (e.g., vector database node + AI node)</font> | ✅<font style="color:rgb(25, 27, 31);"> Designed specifically for RAG; features deep document parsing (OCR, structure extraction, etc.) + retrieval + citations; provides reliable citation-backed Q&A</font> |
| <font style="color:rgb(25, 27, 31);">AI Agent Capabilities</font> | ✅<font style="color:rgb(25, 27, 31);"> Supports an Agent framework based on LLM function calling or ReAct; allows adding pre-built/custom tools; includes 50+ built-in tools (e.g., Google Search, DALL·E, WolframAlpha)</font> | ✅<font style="color:rgb(25, 27, 31);"> Supports AI Agent flows, enabling LangChain agents to call external services; also allows HTTP nodes to call any API for agent-like behavior</font> | ⚠️<font style="color:rgb(25, 27, 31);"> Basic Support: Introduces the "Agentic RAG" concept, allowing external searches (e.g., Wiki, PubMed operators) within retrieval flows; but lacks a general-purpose Agent tool framework</font> |
| <font style="color:rgb(25, 27, 31);">Data Processing Capability</font> | ⚠️<font style="color:rgb(25, 27, 31);"> Text-Focused: Prioritizes AI-related data processing (prompts, vectors, etc.); supports dataset ETL and template transformation nodes; not designed as a general ETL solution</font> | ✅<font style="color:rgb(25, 27, 31);"> Powerful: Handles diverse data types; supports nodes for format conversion, filtering, delays, and custom code for complex logic</font> | ⚠️<font style="color:rgb(25, 27, 31);"> Specialized: Focuses on document parsing/processing (layout analysis, table structure extraction, etc.); optimized for knowledge base construction, not suitable as a general-purpose data pipeline</font> |


### 
### <font style="color:rgb(13, 18, 57);">Standard Protocol Layer: The Strategic Battleground</font>
![](https://intranetproxy.alipay.com/skylark/lark/0/2025/png/51756374/1748500467792-b3ff1765-29ae-4c1a-b6dd-c98d833ad977.png)



**<font style="color:rgb(13, 18, 57);">2022: The Wild West Era</font>**  
<font style="color:rgb(13, 18, 57);">When ChatGPT emerged, early developers experimented with ad-hoc prompt engineering to enable tool interaction - resulting in inconsistent implementations and suboptimal performance.</font>



**<font style="color:rgb(13, 18, 57);">2023: First Standardization Attempt</font>**  
<font style="color:rgb(13, 18, 57);">OpenAI's GPT4-0613 introduced Function Calling capabilities, marking initial standardization. However, developers still struggled with multi-function coordination and poor extensibility.</font>



**<font style="color:rgb(13, 18, 57);">2024: MCP Changes the Game</font>**  
<font style="color:rgb(13, 18, 57);">Anthropic's Model Context Protocol (MCP), open-sourced in November 2024, standardized agent-tool communication. By Q1 2025, MCP became the de facto standard with widespread model support.</font>



**<font style="color:rgb(13, 18, 57);">2025: Protocol Wars Begin</font>**

+ <font style="color:rgb(13, 18, 57);">April: Google open-sourced the Agent2Agent (A2A) protocol. Unlike MCP, which focuses on enabling individual agents, A2A establishes standards for communication and interoperability between multiple agent applications.</font>
+ <font style="color:rgb(13, 18, 57);">May: CopilotKit launched the Agent-User Interaction (AG-UI) protocol, which rapidly gained traction with 2.2K GitHub stars in its first week. AG-UI standardizes the interaction layer between backend tools and frontend user interfaces in agent systems.</font>

![](https://intranetproxy.alipay.com/skylark/lark/0/2025/gif/51756374/1748084132597-8c3a001d-a598-4509-bd2a-9e76534ec054.gif)



<font style="color:rgb(34, 34, 34);">The emergence of MCP, A2A, and AG-UI signals a clear trajectory: LLM applications are evolving toward a microservices architecture. In this future:</font>

+ <font style="color:rgb(34, 34, 34);">Specialized Agents/MCPs will be independently deployable services accessible over the internet.</font>
+ <font style="color:rgb(34, 34, 34);">Standardized configurations will allow developers or users to locally build and launch services on demand.</font>

<font style="color:rgb(34, 34, 34);">This evolution brings both traditional microservice challenges (configuration management, version control, security authentication, data privacy, service orchestration) and LLM-specific complexities (GPU elastic scheduling, cross-node context sharing, multimodal coordination, prompt injection defense, output compliance, granular billing, and intelligent quota management).</font>



<font style="color:rgb(51, 51, 51);">Facing these challenges, the technical standards landscape may partially retain existing protocols but will </font>**<font style="color:rgb(51, 51, 51);">require native innovations</font>**<font style="color:rgb(51, 51, 51);">—such as defining metadata standards for large model services, streaming communication protocols, multimodal interaction protocols, service monitoring protocols, and federated inference protocols. At the practical implementation level, the open-source ecosystem will become the crucial battleground: pioneers who dominate standard-setting can leverage protocol advantages to bind developer toolchains (e.g., frameworks, SDKs), thereby forming a closed-loop technical ecosystem from interface specifications to operational practices. This will ultimately enable the construction of an ecological moat in the Model-as-a-Service (MaaS) era.</font>



<font style="color:rgb(34, 34, 34);">As LLM services accelerate, the standard protocol layer will become a strategic stronghold for leading players. Over the next 1-2 years, we anticipate intense ecosystem positioning wars. Protocols that successfully balance </font>**<font style="color:rgb(34, 34, 34);">technical foresight</font>**<font style="color:rgb(34, 34, 34);"> with </font>**<font style="color:rgb(34, 34, 34);">developer experience</font>**<font style="color:rgb(34, 34, 34);"> will gain dominant influence, driving scalable innovation across the LLM landscape.</font>



### <font style="color:rgb(13, 18, 57);">The Irresistible Vibe Coding Software Development Paradigm</font>
![](https://intranetproxy.alipay.com/skylark/lark/0/2025/png/51756374/1748500482778-385a7b8c-8198-43da-89cb-6fccf2cb09f4.png)



Will Programmers Be the First Replaced by AI? Just months ago, this existential question haunted developers as GitHub Copilot began auto-completing code. But when AI-powered IDEs started generating entire projects, resistance gave way to adoption—ushering in the era of Vibe Coding, where intuitive, AI-assisted development becomes the new norm.



![](https://intranetproxy.alipay.com/skylark/lark/0/2025/png/51756374/1748101185404-524d882d-fa3c-42d7-a752-fd09cd41ce13.png)



Our extensive research into prominent closed-source AI development tools and leading open-source projects reveals a distinct market dichotomy:



**Major tech companies have rapidly entered the AI coding space, primarily with closed-source offerings** like GitHub Copilot, Amazon Q Developer, Huawei's CodeArts Snap, Alibaba's Tongyi Lingma, ByteDance's Trae, and Ant Group's CodeFuse. These industry giants benefit from internal deployment scenarios that enable rapid iteration, but face limitations from over-reliance on proprietary data (restricting generalization capabilities) and lengthy intracompany processes that might slow innovation. This creates both advantages and constraints for large firms developing coding assistance tools.



**Interestingly In contrast, startup ventures and small development teams have demonstrated remarkable agility in producing impactful open-source projects that quickly gain traction within the community.** A prime example is Continue's "continuedev" project, which has garnered substantial attention in open-source circles through lean operations and flexible innovation mechanisms. The AI coding domain remains uniquely accessible, representing one of the few technical fields where smaller entities can compete effectively against industry titans like OpenAI and Google without being disadvantaged by resource disparities. The sector's potential was further underscored by OpenAI's reported $3 billion acquisition offer for AI development tool Windsurf in early May this year.



When analyzing top GitHub projects along dimensions of intelligence sophistication and target user expertise, we've mapped these trending AI coding projects across four quadrants:

![](https://intranetproxy.alipay.com/skylark/lark/0/2025/png/51756374/1748178686068-145ea85f-1073-4db4-8ef8-efed1138f708.png)



We see **AI coding tools are advancing beyond basic snippet generation to tackle full-scale development workflows** - though substantial challenges remain in achieving true engineering capability. While current leaders like Continue and Cline excel at code completion and basic API calls, they still fall short of being true development agents. 



Existing systems struggle with semantic validation, multi-language coordination, and security-sensitive code generation - particularly when refactoring complex, large-scale codebases where success rates remain disappointing. The path forward requires breakthroughs in Context Aawareness and Domain Knowledge Integration. Within two years, advances in code verification (combining formal methods with symbolic execution), multimodal training data (merging code, documentation and runtime logs), and improved developer feedback systems should enable AI coding assistants to handle more routine tasks - though human oversight will remain crucial for critical decisions.



<font style="color:rgb(51, 51, 51);">Amid these current popular projects, we may also recall once-prominent initiatives like Devika, TabNine, and GPT-Pilot, which have since faded into obscurity. Their decline not only highlights the natural evolution of the AI development landscape but also reveals a deeper market fragmentation—as divergent technical priorities and user needs carve distinct niches within the AI ecosystem: Established commercial products (e.g., GitHub Copilot, Devin, and Cursor) and open-source tools have divided the market, leaving projects with homogenized features or slow iteration (such as Devika and GPT-Pilot) struggling to survive. Meanwhile, prominent open-source projects like GPT Engineer—which evolved into the commercialized product Lovable through successful open-source practices—have demonstrated the dynamic interplay between open-source innovation and closed-source commercialization. Notably, GPT Engineer, once a star project in AI application development, is now abandoned due to the team’s shift in focus, highlighting how even highly adopted open-source projects can face maintenance challenges as priorities evolve.</font>

![](https://intranetproxy.alipay.com/skylark/lark/0/2025/png/51756374/1748179839448-7c2e819f-8523-4ed3-91c2-3d1055a82457.png)

### 
### <font style="color:rgb(13, 18, 57);">The Shifting Boundaries of Vector Indexing and Storage</font>
![](https://intranetproxy.alipay.com/skylark/lark/0/2025/png/51756374/1748500494335-e9b6a0a8-0439-42bd-9895-6e206c873494.png)



The evolution of vector databases can be described as a journey from **"explosive hype to rational consolidation."** Around February 2023, projects like Qdrant and Chroma saw an unprecedented surge in attention, each amassing over 5,000 GitHub stars. However, this initial frenzy **failed to sustain long-term momentum.**



![](https://intranetproxy.alipay.com/skylark/lark/0/2025/png/51756374/1748081404279-82a1b038-9614-4495-94ab-f3f640649e32.png)



<font style="color:rgb(51, 51, 51);">During the overall development period from 2024 to 2025, the attention gained by most projects has stabilized with minimal variation, showing no significant disparities. On the OpenRank trend, Milvus—an early open-source project under the neutral stewardship of the LF AI & Data Foundation—has consistently maintained a stable leadership position. Meanwhile, the broader technical landscape appears to function like parallel tracks, advancing steadily forward in unison.</font>

![](https://intranetproxy.alipay.com/skylark/lark/0/2025/png/51756374/1748081415744-f2156f7d-ed79-4190-82bf-763e213bbaa2.png)



Several factors likely contributed to this equilibrium:

1. **Open-source is not the sole market choice:** During this period, purely commercial competitors like Pinecone and KDB.AI have emerged. Notably, Pinecone has demonstrated strong product capabilities and robust market expansion, challenging the dominance of open-source alternatives.
2. **Vectorization upgrades in traditional big data systems:** Over time, legacy databases have introduced vectorization plugins or vector search engines (e.g., pgvector). This includes widely adopted databases like PostgreSQL, MongoDB Atlas, OpenSearch, and ElasticSearch. These developments have eroded the competitive advantage of pure vector databases by offering integrated solutions within established ecosystems.
3. **OpenCore model prioritizes ecosystem over core activity:** Similar to traditional databases, vector databases often adopt the OpenCore model, where commercial companies focus less on the core’s community activity (e.g., GitHub stars, PRs) and more on building a competitive ecosystem around the core. In this model, a functional and complete open-source core is essential, but its long-term maintenance and community engagement are secondary to the commercial entity’s strategic goals. The true value lies in extending the core into proprietary tools, services, and integrations that drive revenue and lock-in.



**This raises another discussion: **

**Are vector databases redundant technologies?** Could traditional databases paired with vector search middleware adequately serve AI application needs?

<font style="color:rgb(51, 51, 51);">The data suggests no. Community data shows that pgvector’s trend is declining, as large-scale models are predominantly deployed in mid-to-large enterprises where horizontal scalability and enterprise-grade capabilities (e.g., cloud-native compatibility, security, and systematic support for existing AI/ML frameworks) are non-negotiable. Commercial products like Zilliz—built on open-source foundations—excel in these areas, offering robust cloud-native architectures, multi-tenancy support, and end-to-end enterprise integration. These commercially supported solutions have gained strong market traction, while pure vector search engines currently lack the infrastructure to deliver such comprehensive enterprise services.</font>



<font style="color:rgb(51, 51, 51);">The development trajectories of vLLM and SGLang highlight a critical insight: </font>**<font style="color:rgb(51, 51, 51);">technical 'thinness' is not the core issue; rather, the availability of iterative space and paradigm shifts determines long-term viability</font>**<font style="color:rgb(51, 51, 51);">. In the case of vector-based technologies, the demands, scenarios, and algorithms are highly specific, leaving limited room for innovation in development. Meanwhile, despite the growing volume of unstructured data, better solutions—such as multimodal models or ecosystem players—have yet to reach scale. This lack of breakthroughs results in relatively slow and stable iterative progress in the vector layer’s optimization.</font>



Unlike the breakneck competition at the application layer, the vector database space exhibits remarkable stability—early innovators haven't been displaced by new disruptors. The waves of change here arrive as swells rather than tsunamis.



### <font style="color:rgb(13, 18, 57);">The Evolution of Multimodal Data Governance in the Age of LLMs</font>
![](https://intranetproxy.alipay.com/skylark/lark/0/2025/png/51756374/1748500503691-64a877c7-4048-47c2-9dc9-dbeea33b054d.png)



The concept of data lakes emerged during the big data era, addressing the need to store, retrieve, and preprocess multimodal data, while data catalogs fulfilled the requirement for unified management of massive, diverse data assets within data lake and lakehouse architectures. Now, in the era of large language models, one truth reigns supreme: it's all about the data, the data, and once more, the data. This raises the question: how has the open-source community evolved around technologies and projects governing multimodal, multi-source data during this transformative wave?



In data lake table formats, **Apache Iceberg, Apache Hudi, Apache Paimon**, and **Delta Lake** have formed a "quadropoly" within the lakehouse ecosystem. Iceberg has solidified its position as the universal framework for open-source lakehouses, while Hudi and Paimon excel in real-time incremental processing. Delta Lake continues its steady progress backed by vendor support. These technologies are poised to both compete with and learn from one another, driving continuous advancement in data lake storage to support reliable management of massive unstructured data.



![](https://intranetproxy.alipay.com/skylark/lark/0/2025/png/51756374/1748178424336-6ae50820-dffd-4d74-87ce-62ee277b5818.png)



The metadata governance and data catalog space sees **OpenMetadata** and **DataHub** maintaining their leadership with increasingly sophisticated features, while newcomers like **Apache Gravitino** and open-source **Unity Catalog** emerge as potential disruptors, hinting at the formation of next-generation unified platforms for data and AI governance. Notably, these tools are expanding their focus to include unstructured data and AI assets, aligning with the broader data governance needs of the LLM era.  
![](https://intranetproxy.alipay.com/skylark/lark/0/2025/png/51756374/1748081358579-c6905c65-d09d-486a-900a-35af84f330ce.png)

When examining the collaborative networks across all projects in the Landscape, it becomes apparent that big data systems currently occupy a relatively peripheral position in the LLM development ecosystem. This may stem from the inherently less interconnected nature of big data developers compared to their AI counterparts. Nevertheless, this observation underscores that the convergence of big data and AI ecosystems remains a work in progress.

Looking ahead, as foundational models become more deeply embedded within data infrastructure, we may witness tighter integration between these domains—whether through big data projects delivering high-quality data for machine learning tasks, or through models providing intelligent support for data governance. This bidirectional synergy could fundamentally reshape how we approach data management in the age of LLMs.

![](https://intranetproxy.alipay.com/skylark/lark/0/2025/png/51756374/1748178939901-b45232c8-07b2-4990-9476-4fea60a5b3ca.png)



### <font style="color:rgb(13, 18, 57);">The Ongoing Battle in Model Serving and Inference</font>
![](https://intranetproxy.alipay.com/skylark/lark/0/2025/png/51756374/1748500524024-ad85af8e-8f72-4223-92ad-85164bbc379a.png)

![](https://intranetproxy.alipay.com/skylark/lark/0/2025/png/51756374/1748183060729-14a96f0a-16ec-40b5-ade6-b46ae2463f39.png)



As large language models move into widespread deployment, three critical factors have emerged as make-or-break for application deployment: inference efficiency, resource utilization, and deployment flexibility. Since 2023, the market has seen an explosion of model serving tools competing head-to-head over performance and ecosystem advantages—a heated race that shows no signs of cooling. The Top 10 rankings in model serving tools remain fluid, with new contenders like Tsinghua University's KTransformers (July 2024) and NVIDIA's Dynamo (March 2025) continually shaking up the field and attracting developer mindshare.

![](https://intranetproxy.alipay.com/skylark/lark/0/2025/gif/85156528/1748104496830-99fb20c1-d1b2-493e-8923-b6a305d10821.gif)

<font style="color:rgb(64, 64, 64);">Standing out in both rankings and momentum are</font>**<font style="color:rgb(64, 64, 64);"> vLLM and SGLang—currently the two most prominent inference engines in the LLM space</font>**<font style="color:rgb(64, 64, 64);">, </font>**<font style="color:rgb(64, 64, 64);">both recommended by DeepSeek.</font>**<font style="color:rgb(64, 64, 64);"> </font><font style="color:rgb(51, 51, 51);">According to OpenRank trends, the communities of vLLM and SGLang continue to expand. In Q4 2024, vLLM's growth temporarily plateaued, while SGLang experienced rapid iteration, achieving an average OpenRank growth rate of 12% in the same quarter. However, as 2025 began, vLLM released its v1 major version with a core architecture overhaul, reigniting its growth trajectory. This shift triggered a new 'AI arms race' in the inference engine ecosystem: in Q1 2025, vLLM's OpenRank grew at 17%, while SGLang surged to 31%.</font>

<font style="color:rgb(51, 51, 51);"></font>

<font style="color:rgb(64, 64, 64);">This duel carries a notable academic pedigree. UC Berkeley—the birthplace of transformative systems like Spark and Ray—again demonstrates its open-source alchemy: vLLM originated from Berkeley's SkyLab, sharing DNA with its predecessors, while SGLang emerged from LMSYS, a multi-university (including UCB) research consortium that also created the influential benchmark platform Chatbot Arena.</font>

<font style="color:rgb(64, 64, 64);"></font>

**Community Comparison Between vLLM and SGLang**

| <font style="background-color:rgba(253,58,184,1);"></font> | **<font style="color:#FFFFFF;background-color:rgba(253,58,184,1);">vLLM</font>** | **<font style="color:#FFFFFF;background-color:rgba(253,58,184,1);">SGLang</font>** |
| --- | --- | --- |
| **Project Influence (OpenRank)** | 2025 Average: 615<br/>2025 Growth Rate: 17% | 2025 Average: 269<br/>2025 Growth Rate: 31% |
| **Founding Organization** | SkyLab, UC Berkeley | LMSYS, an open research organization co-initiated by UC Berkeley, Stanford, and CMU. |
| **Key Developers** | [DarkLight1337](https://github.com/DarkLight1337), HKUST<br/>[youkaichao](https://github.com/youkaichao), Tsinghua<br/>[WoosukKwon](https://github.com/WoosukKwon), UCB | [merrymercy](https://github.com/merrymercy), xAI<br/>[zhyncs](https://github.com/zhyncs), <font style="color:rgb(31, 35, 40);">Baseten</font><br/>[zhaochenyang20](https://github.com/zhaochenyang20), UCLA |
| **Developer Distribution** | United States (33.2%)<br/>China (30.8%) | China (49.2%)<br/>United States (27.5%) |
| **Community Size** | Contributors: 449<br/>Participants: 12,332 | Contributors: 1,134<br/>Participants: 2,232 |




<font style="color:rgb(51, 51, 51);">The model service landscape is </font>**<font style="color:rgb(51, 51, 51);">far more diverse than just vLLM and SGLang</font>**<font style="color:rgb(51, 51, 51);">. </font>

**<font style="color:rgb(51, 51, 51);">Ollama & llama.cpp: Lightweight Powerhouses for Edge Inference and On-Premise Deployment</font>**

+ <font style="color:rgb(51, 51, 51);">A common developer workflow involves using llama.cpp for model training, quantization, and performance tuning, followed by Ollama for rapid deployment and service management. Beyond their recent 1-month rankings as 3rd and 4th in the model service category, they occupy top-tier positions in the broader ecosystem, underscoring their critical role in democratizing AI.</font>

**<font style="color:rgb(51, 51, 51);">KTransformers: A Breakthrough for Ultra-Scale Parameter Scenarios</font>**

+ KTransformers made waves in February 2025 when Tsinghua's KVCache.AI team demonstrated running full 671B parameter models (DeepSeek-R1/V3) on consumer hardware (24GB GPU + 382GB RAM) with 3-28x speedups. The achievement triggered a 34x OpenRank spike, drawing 736 contributors and surpassing 10K GitHub stars within weeks—a testament to the demand for breakthroughs in extreme-scale inference.

![](https://intranetproxy.alipay.com/skylark/lark/0/2025/png/85156528/1748255954661-35298c87-2d3b-458c-9c2b-64c1e46d8376.png)

### 
### <font style="color:rgb(13, 18, 57);">The PyTorch-Centric Training Ecosystem</font>
![](https://intranetproxy.alipay.com/skylark/lark/0/2025/png/51756374/1748500531832-f83f7f40-7e06-460a-b0e0-de866f894783.png)

![](https://intranetproxy.alipay.com/skylark/lark/0/2025/png/85156528/1748176252950-e29249ad-675c-463b-99d0-bbf2867ee1a5.png)

PyTorch has undeniably become the dominant force and de facto standard in today's LLM development landscape. Its modular and lightweight open design propelled it past TensorFlow in 2020, establishing itself as the foundational infrastructure for deep learning in the era of large language models, while frameworks like TensorFlow, MXNet, and Caffe faded into obsolescence.

![](https://intranetproxy.alipay.com/skylark/lark/0/2025/png/51756374/1748081293286-790276e8-d4f4-42ce-ab2e-d7afccb5c98e.png)



In September 2022, Meta transferred PyTorch's governance to the Linux Foundation (LF), establishing the PyTorch Foundation as an independent entity. Through PyTorch's nearly overwhelming ecosystem gravitational pull, this sub-foundation has grown into a powerful umbrella organization. In March 2025, the inference engine [SGLang joined the PyTorch ecosystem](https://pytorch.org/blog/sglang-joins-pytorch/); I<font style="color:rgb(51, 51, 51);">n May 2025, the inference engine vLLM and distributed training platform DeepSpeed also announced their </font>[joining of the PyTorch Foundation](https://pytorch.org/blog/press-release-pytorch-foundation-expands-welcomes-projects-vllm-deepspeed/).

****

<font style="color:rgb(31, 35, 40);">While PyTorch's development is now governed through this neutral, independent foundation, community data still reveals Meta's substantial behind-the-scenes influence. The repository's top contributors include Meta employees: ezyang (3,280 commits), jerryzh168 (1,216 commits), and soumith (1,151 commits), all identifiable as Meta staff on GitHub. At the time of reporting, over 9,000 pull requests (9% of all PRs) carried the "fb-exported" label - strong evidence of code developed and reviewed internally at Meta before being synchronized with GitHub.</font>



## Acknowledgments
This insight report reflects Ant Group's perspective as a technology enterprise, utilizing X-lab's OpenRank evaluation metrics alongside extensive consultations with Ant's technical experts and open-source community developers. We deeply appreciate all contributors for their invaluable insights. We welcome collaboration to further enrich these ecosystem observations.



Full Author List:

Xia Xiaoya, Bian Sikang, Dong Chao, Wang Xu (AntOSS)

Zhao Shengyu, Han Fanyu, Peng Jiaheng, Zhang Zhen, Wang Wei (X-lab<font style="background-color:#F1A2AB;"></font>)

